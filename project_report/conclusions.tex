% !TEX root = template.tex

\section{Concluding Remarks}

In this work, we explored different variants of attention based models for keyword spotting. In particular, we found that models based on multi head attention provide slightly higher accuracy with respect to the baseline Att-RNN  model, even if this came with the cost of a higher parameter count. Deeper convolutional blocks didn't prove to be beneficial, even if this could be due to a too simplistic design for the residual layers. Similarly to many works in the literature, we used the top-1 accuracy as the only metric, but this is not a complete way to evaluate a KWS model. For example, authors in \cite{dnns2014chen}\cite{convnns2015sainath}\cite{streamingkws2020Rybakov} make audio streaming tests to evaluate the false reject and false alarm rate, as well as system latency, to have additional tools for evaluation. Also, for this project the models were trained just one time due to the limited computational capabilites; this fact makes the reported results not too statistically relevant. To perform a more rigorous statistical analysis, one should train the models more times and use an avarage of the test set accuracies among the runs, computing confidence intervals for the final accuracy. Furthermore, additional experiments regarding attention mechanisms could be done starting from the Keyword Transformer architecture; even if the KWT has an extremely heavy memory footprint, it could be worth experimenting lighter variations of it.

In conclusion, this was a very instructive project to work on: I had the opportunity to study a lot of modern machine learning literature and to understand more complex architectures based on the attention mechanism. I also think that this report \LaTeX template was extremely useful and well done, and it will surely be a very useful tool for the future. Besides the part involving the study of the literature, the most difficult part of this work, in my experience, was to build a working input pipeline, both for technical reasons (due to the limitations of my hardware) and for the difficulty to find information online. While it is true that the Labs were extremely useful and essential, especially on the part regarding the \verb|tf.data.Dataset| API, while working on the project I often came across errors which were really hard to debug mostly because of my unawareness of how Tensorflow really works under the hood (see for example the difference between Graph execution and Eager execution). Besides this aspect, I think that the course gave me strong knowledge foundations in order to complete the project.

\label{sec:conclusions}
%
%\red{This section should take max half a page, I personally find it difficult to come up with really useful observations, I mean ones that bring a new contribution with respect to what you have already expounded in the ``Results'' section. In case you have some serious stuff to write, you may also extend the section to 3/4 of a page :-).}\\
%
%In many papers, here you find a summary of what done. It is basically an abstract where instead of using the present tense you use the past participle, as you refer to something that you have already developed in the previous sections. While I did it myself in the past, I now find it rather useless.\\ 
%
%\MR{\textbf{What I would like to see here is:} 
%\begin{enumerate}
%\item a very short summary of what done, 
%\item some (possibly) intelligent observations on the relevance and {\it applicability} of your algorithms / findings, 
%\item what is still missing, and can be added in the future to extend your work.\\
%\end{enumerate}
%The idea is that this section should be {\it useful} and not just a repetition of the abstract (just \mbox{re-phrased} and written using a different tense...).}\\
%
%\red{\textbf{Moreover:} being a project report, I would also like to see a specific paragraph stating 
%\begin{enumerate}
%\item[4)] what you have learned, and 
%\item[5)] any difficulties you may have encountered.
%\end{enumerate}}
